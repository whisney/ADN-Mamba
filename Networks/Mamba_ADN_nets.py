import torch
import torch.nn as nn
import functools
import torch.nn.functional as F
from torch.nn.utils import spectral_norm
from copy import deepcopy
from mamba_ssm import Mamba

class MambaLayer(nn.Module):
    def __init__(self, dim, d_state=16, d_conv=4, expand=2):
        super().__init__()
        self.dim = dim
        self.norm = nn.LayerNorm(dim)
        self.mamba = Mamba(
            d_model=dim,  # Model dimension d_model
            d_state=d_state,  # SSM state expansion factor
            d_conv=d_conv,  # Local convolution width
            expand=expand,  # Block expansion factor
        )

    def forward(self, x):
        if x.dtype == torch.float16:
            x = x.type(torch.float32)
        B, C = x.shape[:2]
        assert C == self.dim
        n_tokens = x.shape[2:].numel()
        img_dims = x.shape[2:]
        x_flat = x.reshape(B, C, n_tokens).transpose(-1, -2)
        x_norm = self.norm(x_flat)
        x_mamba = self.mamba(x_norm)
        out = x_mamba.transpose(-1, -2).reshape(B, C, *img_dims)
        return out

class LayerNorm(nn.Module):
    def __init__(self, num_features, eps=1e-5, affine=True):
        super(LayerNorm, self).__init__()
        self.num_features = num_features
        self.eps = eps
        self.affine = affine

        if self.affine:
            self.gamma = nn.Parameter(torch.Tensor(num_features).uniform_())
            self.beta = nn.Parameter(torch.zeros(num_features))

    def forward(self, x):
        x = F.layer_norm(x, x.shape[1:], eps=self.eps)

        if self.affine:
            shape = [1, -1] + [1] * (x.dim() - 2)
            x = x * self.gamma.view(*shape) + self.beta.view(*shape)
        return x


pad_dict = dict(
    zero=nn.ZeroPad2d,
    reflect=nn.ReflectionPad2d,
    replicate=nn.ReplicationPad2d)

conv_dict = dict(
    conv2d=nn.Conv2d,
    deconv2d=nn.ConvTranspose2d)

norm_dict = dict(
    none=lambda x: lambda x: x,
    spectral=lambda x: lambda x: x,
    batch=nn.BatchNorm2d,
    instance=nn.InstanceNorm2d,
    layer=LayerNorm)

activ_dict = dict(
    none=lambda: lambda x: x,
    relu=lambda: nn.ReLU(inplace=True),
    lrelu=lambda: nn.LeakyReLU(0.2, inplace=True),
    prelu=lambda: nn.PReLU(),
    selu=lambda: nn.SELU(inplace=True),
    tanh=lambda: nn.Tanh())


class ConvolutionBlock(nn.Module):
    def __init__(self, conv='conv2d', norm='instance', activ='relu', pad='zero', padding=0, **conv_opts):
        super(ConvolutionBlock, self).__init__()

        self.pad = pad_dict[pad](padding)
        self.conv = conv_dict[conv](**conv_opts)

        out_channels = conv_opts['out_channels']
        self.norm = norm_dict[norm](out_channels)
        if norm == "spectral": self.conv = spectral_norm(self.conv)

        self.activ = activ_dict[activ]()

    def forward(self, x):
        return self.activ(self.norm(self.conv(self.pad(x))))


class ResidualBlock(nn.Module):
    def __init__(self, channels, norm='instance', activ='relu', pad='zero'):
        super(ResidualBlock, self).__init__()

        block = []
        block += [ConvolutionBlock(
            in_channels=channels, out_channels=channels, kernel_size=3,
            stride=1, padding=1, norm=norm, activ=activ, pad=pad)]
        block += [ConvolutionBlock(
            in_channels=channels, out_channels=channels, kernel_size=3,
            stride=1, padding=1, norm=norm, activ='none', pad=pad)]
        self.model = nn.Sequential(*block)

    def forward(self, x): return self.model(x) + x


class FullyConnectedBlock(nn.Module):
    def __init__(self, input_ch, output_ch, norm='none', activ='relu'):
        super(FullyConnectedBlock, self).__init__()

        self.fc = nn.Linear(input_ch, output_ch, bias=True)
        self.norm = norm_dict[norm](output_ch)
        if norm == "spectral": self.fc = spectral_norm(self.fc)
        self.activ = activ_dict[activ]()

    def forward(self, x): return self.activ(self.norm(self.fc(x)))


class Encoder(nn.Module):
    def __init__(self, input_ch, base_ch, num_down, num_residual, unm_mamba, res_norm='instance', down_norm='instance'):
        super(Encoder, self).__init__()

        self.conv0 = ConvolutionBlock(
            in_channels=input_ch, out_channels=base_ch, kernel_size=7, stride=1,
            padding=3, pad='zero', norm=down_norm, activ='relu')

        output_ch = base_ch
        for i in range(1, num_down + 1):
            m = ConvolutionBlock(
                in_channels=output_ch, out_channels=output_ch * 2, kernel_size=4,
                stride=2, padding=1, pad='zero', norm=down_norm, activ='relu')
            setattr(self, "conv{}".format(i), m)
            output_ch *= 2

        for i in range(num_residual):
            setattr(self, "res{}".format(i),
                    ResidualBlock(output_ch, pad='zero', norm=res_norm, activ='relu'))

        for i in range(unm_mamba):
            setattr(self, "mamba{}".format(i),
                    MambaLayer(dim=output_ch))

        self.layers = [getattr(self, "conv{}".format(i)) for i in range(num_down + 1)] + \
                      [getattr(self, "res{}".format(i)) for i in range(num_residual)] + \
                      [getattr(self, "mamba{}".format(i)) for i in range(unm_mamba)]

    def forward(self, x):
        sides = []
        for layer in self.layers:
            x = layer(x)
            sides.append(x)
        return x, sides[::-1]


class Decoder(nn.Module):
    def __init__(self, output_ch, base_ch, num_up, num_residual, unm_mamba, num_sides, res_norm='instance', up_norm='layer',
                 fuse=False):
        super(Decoder, self).__init__()
        input_ch = base_ch * 2 ** num_up
        input_chs = []

        for i in range(unm_mamba):
            setattr(self, "mamba{}".format(i),
                    MambaLayer(dim=input_ch))
            input_chs.append(input_ch)


        for i in range(num_residual):
            setattr(self, "res{}".format(i),
                    ResidualBlock(input_ch, pad='zero', norm=res_norm, activ='lrelu'))
            input_chs.append(input_ch)

        for i in range(num_up):
            m = nn.Sequential(
                nn.Upsample(scale_factor=2, mode="nearest"),
                ConvolutionBlock(
                    in_channels=input_ch, out_channels=input_ch // 2, kernel_size=5,
                    stride=1, padding=2, pad='zero', norm=up_norm, activ='lrelu'))
            setattr(self, "conv{}".format(i), m)
            input_chs.append(input_ch)
            input_ch //= 2

        m = ConvolutionBlock(
            in_channels=base_ch, out_channels=output_ch, kernel_size=7,
            stride=1, padding=3, pad='zero', norm='none', activ='tanh')
        setattr(self, "conv{}".format(num_up), m)
        input_chs.append(base_ch)

        self.layers = [getattr(self, "mamba{}".format(i)) for i in range(unm_mamba)] + \
                      [getattr(self, "res{}".format(i)) for i in range(num_residual)] + \
                      [getattr(self, "conv{}".format(i)) for i in range(num_up + 1)]

        # If true, fuse (concat and conv) the side features with decoder features
        # Otherwise, directly add artifact feature with decoder features
        if fuse:
            input_chs = input_chs[-num_sides:]
            for i in range(num_sides):
                setattr(self, "fuse{}".format(i),
                        nn.Conv2d(input_chs[i] * 2, input_chs[i], 1))
            self.fuse = lambda x, y, i: getattr(self, "fuse{}".format(i))(torch.cat((x, y), 1))
        else:
            self.fuse = lambda x, y, i: x + y

    def forward(self, x, sides=[]):
        m, n = len(self.layers), len(sides)
        assert m >= n, "Invalid side inputs"

        for i in range(m - n):
            x = self.layers[i](x)

        for i, j in enumerate(range(m - n, m)):
            x = self.fuse(x, sides[i], i)
            x = self.layers[j](x)
        return x


class ADN(nn.Module):
    """
    Image with artifact is denoted as low quality image
    Image without artifact is denoted as high quality image
    """

    def __init__(self, input_ch=1, base_ch=32, num_down=3, num_residual=4, unm_mamba=2, num_sides=4,
                 res_norm='instance', down_norm='instance', up_norm='layer', fuse=True, shared_decoder=False):
        super(ADN, self).__init__()

        self.n = num_down + num_residual + 1 if num_sides == "all" else num_sides
        self.encoder_low = Encoder(input_ch, base_ch, num_down, num_residual, unm_mamba, res_norm, down_norm)
        self.encoder_high = Encoder(input_ch, base_ch, num_down, num_residual, unm_mamba, res_norm, down_norm)
        self.encoder_art = Encoder(input_ch, base_ch, num_down, num_residual, unm_mamba, res_norm, down_norm)
        self.decoder = Decoder(input_ch, base_ch, num_down, num_residual, unm_mamba, self.n, res_norm, up_norm, fuse)
        self.decoder_art = self.decoder if shared_decoder else deepcopy(self.decoder)

    def forward1(self, x_low):
        _, sides = self.encoder_art(x_low)  # encode artifact
        self.saved = (x_low, sides)
        code, _ = self.encoder_low(x_low)  # encode low quality image
        y1 = self.decoder_art(code, sides[-self.n:])  # decode image with artifact (low quality)
        y2 = self.decoder(code)  # decode image without artifact (high quality)
        return y1, y2

    def forward2(self, x_low, x_high):
        if hasattr(self, "saved") and self.saved[0] is x_low:
            sides = self.saved[1]
        else:
            _, sides = self.encoder_art(x_low)  # encode artifact

        code, _ = self.encoder_high(x_high)  # encode high quality image
        y1 = self.decoder_art(code, sides[-self.n:])  # decode image with artifact (low quality)
        y2 = self.decoder(code)  # decode without artifact (high quality)
        return y1, y2

    def forward_lh(self, x_low):
        code, _ = self.encoder_low(x_low)  # encode low quality image
        y = self.decoder(code)
        return y

    def forward_hl(self, x_low, x_high):
        _, sides = self.encoder_art(x_low)  # encode artifact
        code, _ = self.encoder_high(x_high)  # encode high quality image
        y = self.decoder_art(code, sides[-self.n:])  # decode image with artifact (low quality)
        return y


class NLayerDiscriminator(nn.Module):
    """Defines a PatchGAN discriminator

    This class is adopted from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
    """

    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):
        """Construct a PatchGAN discriminator

        Parameters:
            input_nc (int)  -- the number of channels in input images
            ndf (int)       -- the number of filters in the last conv layer
            n_layers (int)  -- the number of conv layers in the discriminator
            norm_layer      -- normalization layer
        """
        super(NLayerDiscriminator, self).__init__()
        if type(norm_layer) is str:
            norm_layer = {
                "layer": nn.LayerNorm,
                "instance": nn.InstanceNorm2d,
                "batch": nn.BatchNorm2d,
                "none": None}[norm_layer]

        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters
            use_bias = norm_layer.func != nn.BatchNorm2d
        else:
            use_bias = norm_layer != nn.BatchNorm2d

        kw = 4
        padw = 1
        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]
        nf_mult = 1
        nf_mult_prev = 1
        for n in range(1, n_layers):  # gradually increase the number of filters
            nf_mult_prev = nf_mult
            nf_mult = min(2 ** n, 8)
            sequence += [
                            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw,
                                      bias=use_bias)] + \
                        ([norm_layer(ndf * nf_mult)] if norm_layer else []) + [nn.LeakyReLU(0.2, True)]

        nf_mult_prev = nf_mult
        nf_mult = min(2 ** n_layers, 8)
        sequence += [
                        nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw,
                                  bias=use_bias)] + \
                    ([norm_layer(ndf * nf_mult)] if norm_layer else []) + [nn.LeakyReLU(0.2, True)]

        sequence += [
            nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map
        self.model = nn.Sequential(*sequence)

    def forward(self, input):
        """Standard forward."""
        return self.model(input)

if __name__ == '__main__':
    encoder = Encoder(input_ch=1, base_ch=16, num_down=3, num_residual=2, unm_mamba=2, res_norm='instance', down_norm='instance').cuda()
    decoder = Decoder(output_ch=1, base_ch=16, num_up=3, num_residual=2, unm_mamba=2, num_sides=4, res_norm='instance', up_norm='layer', fuse=True).cuda()
    x = torch.rand((1, 1, 512, 512)).cuda()
    z, sides = encoder(x)
    print(z.shape)
    y = decoder(z, sides[-4:])
    print(y.shape)